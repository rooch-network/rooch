name: Pruner Long-term Integration Test

on:
  workflow_dispatch:
    inputs:
      inter_cycle_wait_s:
        description: 'Wait time between cycles (seconds) for pruner to work'
        required: false
        default: '120'
        type: choice
        options:
          - '60'
          - '120'
          - '180'
          - '300'
      workload_intensity:
        description: 'Workload intensity level'
        required: false
        default: 'medium'
        type: choice
        options:
          - 'light'
          - 'medium'
          - 'heavy'
      enable_disk_monitoring:
        description: 'Enable real disk usage monitoring'
        required: false
        default: true
        type: boolean

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  CARGO_INCREMENTAL: 0

jobs:
  pruner-long-term-test:
    name: Pruner Long-term Test
    runs-on: self-hosted
    timeout-minutes: 600 # 10 hours max

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: ./.github/actions/rust-setup

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          shared-key: 'pruner-test'
          cache-on-failure: true

      - name: Build Rooch binary (optci profile)
        run: |
          echo "Building Rooch binary with optci profile..."
          cargo build --profile optci --bin rooch
          ls -lh target/optci/rooch

      - name: Setup Node.js
        uses: actions/setup-node@v2
        with:
          node-version: '20.3.1'

      - name: Setup pnpm
        run: |
          npm install pnpm@9.10.0 -g
          pnpm install

      - name: Build test dependencies
        run: |
          pnpm --filter @roochnetwork/test-suite build
          pnpm --filter @roochnetwork/rooch-pruner-e2e exec vitest --version

      - name: Setup disk monitoring
        id: disk-setup
        if: ${{ inputs.enable_disk_monitoring }}
        run: |
          # Create dedicated base directory for test data
          # TestBox will create subdirectories under this base directory
          TEST_BASE_DIR="/tmp/rooch_pruner_test_$(date +%s)"
          mkdir -p "$TEST_BASE_DIR"
          echo "test_base_dir=$TEST_BASE_DIR" >> $GITHUB_OUTPUT
          echo "Test base directory: $TEST_BASE_DIR"

          # Use the monitoring script from scripts directory
          MONITOR_SCRIPT="${{ github.workspace }}/scripts/monitor_disk_usage.sh"
          if [ ! -f "$MONITOR_SCRIPT" ]; then
            echo "ERROR: Monitoring script not found at $MONITOR_SCRIPT" >&2
            exit 1
          fi

          # Ensure script is executable
          chmod +x "$MONITOR_SCRIPT"

          # Start monitoring in background
          "$MONITOR_SCRIPT" "$TEST_BASE_DIR" "/tmp/disk_usage.log" &
          MONITOR_PID=$!
          echo "monitor_pid=$MONITOR_PID" >> $GITHUB_OUTPUT
          echo "Started disk monitor (PID: $MONITOR_PID) for base directory: $TEST_BASE_DIR"
          echo "Using monitoring script: $MONITOR_SCRIPT"

      - name: Determine test parameters
        id: test-params
        run: |
          # Determine workload parameters based on intensity
          case "${{ inputs.workload_intensity }}" in
            light)
              echo "counter_iters=50" >> $GITHUB_OUTPUT
              echo "create_iters=25" >> $GITHUB_OUTPUT
              echo "update_iters=15" >> $GITHUB_OUTPUT
              echo "delete_iters=10" >> $GITHUB_OUTPUT
              echo "cycle_count=5" >> $GITHUB_OUTPUT
              ;;
            medium)
              echo "counter_iters=100" >> $GITHUB_OUTPUT
              echo "create_iters=50" >> $GITHUB_OUTPUT
              echo "update_iters=25" >> $GITHUB_OUTPUT
              echo "delete_iters=20" >> $GITHUB_OUTPUT
              echo "cycle_count=10" >> $GITHUB_OUTPUT
              ;;
            heavy)
              echo "counter_iters=200" >> $GITHUB_OUTPUT
              echo "create_iters=100" >> $GITHUB_OUTPUT
              echo "update_iters=50" >> $GITHUB_OUTPUT
              echo "delete_iters=40" >> $GITHUB_OUTPUT
              echo "cycle_count=15" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: Run pruner long-term test
        id: pruner-test
        env:
          ROOCH_BINARY_BUILD_PROFILE: optci
          TESTBOX_BASE_DIR: ${{ steps.disk-setup.outputs.test_base_dir }}
          # Keep temporary files for debugging and analysis
          TESTBOX_KEEP_TMP: 'true'
          # Unified test configuration
          COUNTER_ITERS: ${{ steps.test-params.outputs.counter_iters }}
          CREATE_ITERS: ${{ steps.test-params.outputs.create_iters }}
          UPDATE_ITERS: ${{ steps.test-params.outputs.update_iters }}
          DELETE_ITERS: ${{ steps.test-params.outputs.delete_iters }}
          CYCLE_COUNT: ${{ steps.test-params.outputs.cycle_count }}
          # Inter-cycle wait: pruner works during this time (monitoring integrated into cycles)
          INTER_CYCLE_WAIT_S: ${{ inputs.inter_cycle_wait_s }}
          SETTLE_MS: '120000'
          # Pruner server config for long-term tests
          BLOOM_BITS: '67108864'
          PRUNER_INTERVAL_S: '30'
          SCAN_BATCH: '50000'
          DELETE_BATCH: '25000'
          # protection_orders: protect N most recent tx_orders
          # Higher values = safer (less aggressive pruning)
          # Use 1 to protect recent states during concurrent workload
          PROTECTION_ORDERS: '1'
        run: |
          echo "Starting pruner long-term test..."
          echo "=========================================="
          echo "Environment Variables Check:"
          echo "  COUNTER_ITERS=$COUNTER_ITERS"
          echo "  CREATE_ITERS=$CREATE_ITERS"
          echo "  UPDATE_ITERS=$UPDATE_ITERS"
          echo "  DELETE_ITERS=$DELETE_ITERS"
          echo "  CYCLE_COUNT=$CYCLE_COUNT"
          echo "  INTER_CYCLE_WAIT_S=$INTER_CYCLE_WAIT_S"
          echo "  TESTBOX_BASE_DIR=$TESTBOX_BASE_DIR"
          echo "  TESTBOX_KEEP_TMP=$TESTBOX_KEEP_TMP"
          echo "=========================================="
          echo "Inter-cycle wait: ${{ inputs.inter_cycle_wait_s }} seconds"
          echo "Intensity: ${{ inputs.workload_intensity }}"
          echo "Test base directory: ${{ steps.disk-setup.outputs.test_base_dir }}"
          echo "Keep temporary files: $TESTBOX_KEEP_TMP"
          
          # Estimate expected time based on actual measurements (~100ms per op)
          TOTAL_OPS=$((COUNTER_ITERS + CREATE_ITERS + UPDATE_ITERS + DELETE_ITERS))
          OPS_TIME_SEC=$((TOTAL_OPS * 100 / 1000))  # ~100ms per op (conservative)
          CYCLE_TIME_SEC=$((OPS_TIME_SEC + INTER_CYCLE_WAIT_S))
          CYCLES_TIME_MIN=$((CYCLE_COUNT * CYCLE_TIME_SEC / 60))
          EXPECTED_MIN=$((CYCLES_TIME_MIN + 12))  # + 12min setup/settle buffer
          echo "Expected test time: approximately $EXPECTED_MIN minutes"
          echo "=========================================="

          # Record start time
          START_TIME=$(date +%s)
          echo "start_time=$START_TIME" >> $GITHUB_OUTPUT

          # Run the test and capture output
          cd sdk/typescript/rooch-pruner-e2e
          
          # Run test and capture exit code
          set +e
          pnpm exec vitest run src/case/pruner-e2e.spec.ts --reporter=verbose 2>&1 | tee test-output.log
          TEST_EXIT_CODE=${PIPESTATUS[0]}
          set -e
          
          # Record end time
          END_TIME=$(date +%s)
          echo "end_time=$END_TIME" >> $GITHUB_OUTPUT
          DURATION=$((END_TIME - START_TIME))
          echo "duration=$DURATION" >> $GITHUB_OUTPUT
          echo "test_exit_code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT
          
          # Summary
          echo "=========================================="
          echo "Test completed in $DURATION seconds ($((DURATION / 60)) minutes)"
          echo "Test exit code: $TEST_EXIT_CODE"
          
          # Check if test report was generated
          if [ -f test-report.json ]; then
            echo "Test report generated successfully"
            echo "Report size: $(wc -c < test-report.json) bytes"
          else
            echo "WARNING: test-report.json was not generated!"
          fi
          echo "=========================================="
          
          # Exit with test exit code
          exit $TEST_EXIT_CODE

      - name: Analyze disk usage
        id: disk-analysis
        if: ${{ inputs.enable_disk_monitoring && always() }}
        run: |
          # Stop monitoring
          if [ -n "${{ steps.disk-setup.outputs.monitor_pid }}" ]; then
            kill ${{ steps.disk-setup.outputs.monitor_pid }} 2>/dev/null || true
          fi

          # Analyze disk usage from monitoring log
          if [ -f /tmp/disk_usage.log ]; then
            # Get peak usage
            PEAK_USAGE=$(awk -F',' '{print $3}' /tmp/disk_usage.log | sort -n | tail -1)
            echo "peak_usage=$PEAK_USAGE" >> $GITHUB_OUTPUT
            
            # Get final usage from all testbox directories
            TEST_BASE_DIR="${{ steps.disk-setup.outputs.test_base_dir }}"
            FINAL_USAGE=0
            if [ -d "$TEST_BASE_DIR" ]; then
              # Calculate total size of all testbox directories using same logic as monitor
              while IFS= read -r dir; do
                # Skip .rooch_test if .rooch_test/data exists (avoid double counting)
                if [[ "$dir" == */.rooch_test ]] && [ -d "${dir}/data" ]; then
                  continue
                fi
                if [ -d "$dir" ]; then
                  DIR_SIZE=$(du -sb "$dir" 2>/dev/null | awk '{print $1}')
                  if [ -n "$DIR_SIZE" ] && [ "$DIR_SIZE" -gt 0 ] 2>/dev/null; then
                    FINAL_USAGE=$((FINAL_USAGE + DIR_SIZE))
                  fi
                fi
              done < <(find "$TEST_BASE_DIR" -type d \( -path "*/testbox-*/.rooch_test/data" -o -path "*/testbox-*/.rooch_test" \) 2>/dev/null)
              echo "final_usage=$FINAL_USAGE" >> $GITHUB_OUTPUT
              
              # Calculate reclaimed space (peak - final)
              if [ -n "$PEAK_USAGE" ] && [ "$PEAK_USAGE" -gt 0 ] && [ -n "$FINAL_USAGE" ]; then
                RECLAIMED=$((PEAK_USAGE - FINAL_USAGE))
                echo "reclaimed=$RECLAIMED" >> $GITHUB_OUTPUT
                
                echo "Peak disk usage: $PEAK_USAGE bytes"
                echo "Final disk usage: $FINAL_USAGE bytes"
                echo "Space reclaimed by pruner: $RECLAIMED bytes"
                
                # Calculate reclaim percentage
                if [ $PEAK_USAGE -gt 0 ]; then
                  RECLAIM_PCT=$(awk "BEGIN {printf \"%.2f\", $RECLAIMED * 100 / $PEAK_USAGE}")
                  echo "reclaim_percentage=$RECLAIM_PCT" >> $GITHUB_OUTPUT
                  echo "Reclaim percentage: $RECLAIM_PCT%"
                fi
              else
                echo "WARNING: Could not calculate final usage or peak usage is 0"
                echo "Peak usage: $PEAK_USAGE"
                echo "Final usage: $FINAL_USAGE"
              fi
            else
              echo "WARNING: Test base directory not found: $TEST_BASE_DIR"
            fi
            
            # Save monitoring log as artifact
            cp /tmp/disk_usage.log disk-usage-timeline.csv
          else
            echo "Disk monitoring log not found"
          fi

      - name: Fetch and analyze Prometheus metrics
        id: metrics
        if: always()
        run: |
          # Find the metrics port from test logs and save metrics snapshot
          METRICS_PORT=$(grep -oP 'metrics.*port.*\K\d+' sdk/typescript/rooch-pruner-e2e/test-output.log || echo "9184")
          echo "metrics_port=$METRICS_PORT" >> $GITHUB_OUTPUT

          # Try to fetch metrics snapshot if server is still running
          if curl -s "http://localhost:$METRICS_PORT/metrics" > metrics-snapshot.txt; then
            echo "Metrics snapshot saved successfully"
          else
            echo "Could not fetch metrics snapshot (server may be stopped)"
          fi

          # Extract metrics from test report JSON if available
          if [ -f sdk/typescript/rooch-pruner-e2e/test-report.json ]; then
            echo "Using metrics from test report JSON"

            # Extract values using jq if available, otherwise use grep
            if command -v jq >/dev/null 2>&1; then
              NODES_DELETED_SWEEP=$(jq -r '.report.prunerMetrics.sweepExpiredDeleted.sum' sdk/typescript/rooch-pruner-e2e/test-report.json 2>/dev/null || echo "0")
              NODES_DELETED_INCR=$(jq -r '.report.prunerMetrics.incrementalSweepDeleted.sum' sdk/typescript/rooch-pruner-e2e/test-report.json 2>/dev/null || echo "0")
              REACHABLE_NODES=$(jq -r '.report.prunerMetrics.reachableNodesScanned.sum' sdk/typescript/rooch-pruner-e2e/test-report.json 2>/dev/null || echo "0")
              DISK_RECLAIMED=$(jq -r '.report.prunerMetrics.diskSpaceReclaimedBytes' sdk/typescript/rooch-pruner-e2e/test-report.json 2>/dev/null || echo "0")
              BLOOM_SIZE=$(jq -r '.report.prunerMetrics.bloomFilterSizeBytes' sdk/typescript/rooch-pruner-e2e/test-report.json 2>/dev/null || echo "0")
            else
              # Fallback to grep-based extraction
              NODES_DELETED_SWEEP=$(grep -oP '"sweepExpiredDeleted":{"sum":\K[\d.]+' sdk/typescript/rooch-pruner-e2e/test-report.json | head -1 || echo "0")
              NODES_DELETED_INCR=$(grep -oP '"incrementalSweepDeleted":{"sum":\K[\d.]+' sdk/typescript/rooch-pruner-e2e/test-report.json | head -1 || echo "0")
              REACHABLE_NODES=$(grep -oP '"reachableNodesScanned":{"sum":\K[\d.]+' sdk/typescript/rooch-pruner-e2e/test-report.json | head -1 || echo "0")
              DISK_RECLAIMED=$(grep -oP '"diskSpaceReclaimedBytes":\K[\d.]+' sdk/typescript/rooch-pruner-e2e/test-report.json | head -1 || echo "0")
              BLOOM_SIZE=$(grep -oP '"bloomFilterSizeBytes":\K[\d.]+' sdk/typescript/rooch-pruner-e2e/test-report.json | head -1 || echo "0")
            fi
          else
            echo "Test report JSON not found, using default values"
            NODES_DELETED_SWEEP=0
            NODES_DELETED_INCR=0
            REACHABLE_NODES=0
            DISK_RECLAIMED=0
            BLOOM_SIZE=0
          fi

          echo "nodes_deleted_sweep=$NODES_DELETED_SWEEP" >> $GITHUB_OUTPUT
          echo "nodes_deleted_incr=$NODES_DELETED_INCR" >> $GITHUB_OUTPUT
          echo "reachable_nodes=$REACHABLE_NODES" >> $GITHUB_OUTPUT
          echo "disk_reclaimed_estimated=$DISK_RECLAIMED" >> $GITHUB_OUTPUT
          echo "bloom_filter_size=$BLOOM_SIZE" >> $GITHUB_OUTPUT

      - name: Generate test report
        if: always()
        run: |
          # Pre-calculate all values before generating report
          START_TIME="${{ steps.pruner-test.outputs.start_time }}"
          END_TIME="${{ steps.pruner-test.outputs.end_time }}"
          DURATION="${{ steps.pruner-test.outputs.duration }}"
          
          # Format timestamps (handle both GNU and BSD date)
          if [ -n "$START_TIME" ] && [ "$START_TIME" != "" ]; then
            START_TIME_FMT=$(date -d "@$START_TIME" '+%Y-%m-%d %H:%M:%S' 2>/dev/null || date -r "$START_TIME" '+%Y-%m-%d %H:%M:%S' 2>/dev/null || echo "N/A")
          else
            START_TIME_FMT="N/A"
          fi
          
          if [ -n "$END_TIME" ] && [ "$END_TIME" != "" ]; then
            END_TIME_FMT=$(date -d "@$END_TIME" '+%Y-%m-%d %H:%M:%S' 2>/dev/null || date -r "$END_TIME" '+%Y-%m-%d %H:%M:%S' 2>/dev/null || echo "N/A")
          else
            END_TIME_FMT="N/A"
          fi
          
          # Format duration in human readable form
          if [ -n "$DURATION" ] && [ "$DURATION" -gt 0 ] 2>/dev/null; then
            DURATION_MIN=$((DURATION / 60))
            DURATION_SEC=$((DURATION % 60))
            DURATION_FMT="${DURATION_MIN}m ${DURATION_SEC}s ($DURATION seconds)"
          else
            DURATION_FMT="N/A"
          fi
          
          # Calculate disk space values in MB
          DISK_RECLAIMED_ESTIMATED="${{ steps.metrics.outputs.disk_reclaimed_estimated }}"
          BLOOM_FILTER_SIZE="${{ steps.metrics.outputs.bloom_filter_size }}"
          PEAK_USAGE="${{ steps.disk-analysis.outputs.peak_usage }}"
          FINAL_USAGE="${{ steps.disk-analysis.outputs.final_usage }}"
          RECLAIMED="${{ steps.disk-analysis.outputs.reclaimed }}"
          
          DISK_RECLAIMED_MB=$(awk "BEGIN {printf \"%.2f\", ${DISK_RECLAIMED_ESTIMATED:-0} / 1024 / 1024}" 2>/dev/null || echo "N/A")
          BLOOM_FILTER_MB=$(awk "BEGIN {printf \"%.2f\", ${BLOOM_FILTER_SIZE:-0} / 1024 / 1024}" 2>/dev/null || echo "N/A")
          PEAK_USAGE_MB=$(awk "BEGIN {printf \"%.2f\", ${PEAK_USAGE:-0} / 1024 / 1024}" 2>/dev/null || echo "N/A")
          FINAL_USAGE_MB=$(awk "BEGIN {printf \"%.2f\", ${FINAL_USAGE:-0} / 1024 / 1024}" 2>/dev/null || echo "N/A")
          RECLAIMED_MB=$(awk "BEGIN {printf \"%.2f\", ${RECLAIMED:-0} / 1024 / 1024}" 2>/dev/null || echo "N/A")
          
          # Calculate accuracy percentage
          if [ -n "$DISK_RECLAIMED_ESTIMATED" ] && [ "$DISK_RECLAIMED_ESTIMATED" != "0" ] && [ "$DISK_RECLAIMED_ESTIMATED" != "" ]; then
            ACCURACY=$(awk "BEGIN {printf \"%.1f\", ${RECLAIMED:-0} * 100 / $DISK_RECLAIMED_ESTIMATED}" 2>/dev/null || echo "N/A")
          else
            ACCURACY="N/A"
          fi
          
          # Generate report using variables (no command substitution needed in heredoc)
          cat > test-report.md << REPORT_EOF
          # Pruner Long-term Integration Test Report

          ## Test Configuration

          - **Workload Intensity**: ${{ inputs.workload_intensity }}
          - **Inter-cycle Wait**: ${{ inputs.inter_cycle_wait_s }} seconds
          - **Start Time**: ${START_TIME_FMT}
          - **End Time**: ${END_TIME_FMT}
          - **Actual Duration**: ${DURATION_FMT}

          ## Workload Parameters

          - **Counter Iterations**: ${{ steps.test-params.outputs.counter_iters }}
          - **Create Iterations**: ${{ steps.test-params.outputs.create_iters }}
          - **Update Iterations**: ${{ steps.test-params.outputs.update_iters }}
          - **Delete Iterations**: ${{ steps.test-params.outputs.delete_iters }}
          - **Cycle Count**: ${{ steps.test-params.outputs.cycle_count }}

          ## Pruner Metrics

          ### Node Statistics
          - **Nodes Deleted (Sweep)**: ${{ steps.metrics.outputs.nodes_deleted_sweep }}
          - **Nodes Deleted (Incremental)**: ${{ steps.metrics.outputs.nodes_deleted_incr }}
          - **Reachable Nodes Scanned**: ${{ steps.metrics.outputs.reachable_nodes }}

          ### Disk Space
          - **Estimated Reclaimed (from metrics)**: ${DISK_RECLAIMED_MB} MB
          - **Bloom Filter Size**: ${BLOOM_FILTER_MB} MB

          REPORT_EOF

          # Add real disk monitoring results if available
          if [ "${{ inputs.enable_disk_monitoring }}" = "true" ]; then
            cat >> test-report.md << DISK_EOF
          ### Real Disk Usage Analysis

          > **Note**: Disk usage monitoring uses peak-to-final difference to measure pruner effectiveness.
          > Since the test continuously writes data while pruner deletes old data, the final size 
          > will be larger than initial. The key metric is: Peak - Final = Reclaimed by Pruner.

          - **Peak Usage (during test)**: ${PEAK_USAGE_MB} MB
          - **Final Usage (after pruner)**: ${FINAL_USAGE_MB} MB
          - **Space Reclaimed**: ${RECLAIMED_MB} MB
          - **Reclaim Percentage**: ${{ steps.disk-analysis.outputs.reclaim_percentage }}% of peak usage

          #### Comparison
          - **Estimated (from metrics)**: ${DISK_RECLAIMED_MB} MB
          - **Actual (from monitoring)**: ${RECLAIMED_MB} MB
          - **Accuracy**: ${ACCURACY}% (actual/estimated)

          DISK_EOF
          fi

          cat >> test-report.md << SUMMARY_EOF
          ## Test Output Summary

          See attached artifacts for full test logs and metrics snapshot.

          ## Test Data Download

          **Test Data Archive**: The complete test data directory has been packaged and uploaded as a separate artifact named \`pruner-test-data-${{ github.run_number }}\`.

          This archive contains:
          - Complete test data directory structure
          - Database files and state snapshots
          - All generated test artifacts and logs
          - \`test-manifest.txt\` with detailed test configuration information

          You can download this artifact from the GitHub Actions run page for detailed offline analysis and debugging.

          SUMMARY_EOF

          cat test-report.md
          echo "Test report generated"

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pruner-test-report-${{ github.run_number }}
          path: |
            sdk/typescript/rooch-pruner-e2e/test-output.log
            sdk/typescript/rooch-pruner-e2e/test-report.json
            test-report.md
            metrics-snapshot.txt
            disk-usage-timeline.csv
          retention-days: 30

      - name: Package and upload test data directory
        if: always() && ${{ inputs.enable_disk_monitoring }}
        run: |
          TEST_BASE_DIR="${{ steps.disk-setup.outputs.test_base_dir }}"
          if [ -n "$TEST_BASE_DIR" ] && [ -d "$TEST_BASE_DIR" ]; then
            echo "Packaging test data directory: $TEST_BASE_DIR"

            # Create archive name with timestamp
            ARCHIVE_NAME="pruner-test-data-${{ github.run_number }}-$(date +%Y%m%d-%H%M%S).tar.gz"

            # Create a manifest file with test information
            cat > "$TEST_BASE_DIR/test-manifest.txt" << MANIFEST_EOF
            Test Run Information:
            ===================
            GitHub Run ID: ${{ github.run_number }}
            Workflow: ${{ github.workflow }}
            Job: ${{ github.job }}
            Repository: ${{ github.repository }}
            Commit: ${{ github.sha }}

            Test Configuration:
            - Workload Intensity: ${{ inputs.workload_intensity }}
            - Inter-cycle Wait: ${{ inputs.inter_cycle_wait_s }} seconds
            - Disk Monitoring: ${{ inputs.enable_disk_monitoring }}
            - Keep Temporary Files: true
            - Test Base Directory: $TESTBOX_BASE_DIR
            - Start Time: ${{ steps.pruner-test.outputs.start_time }}
            - End Time: ${{ steps.pruner-test.outputs.end_time }}
            - Duration: ${{ steps.pruner-test.outputs.duration }} seconds
            - Exit Code: ${{ steps.pruner-test.outputs.test_exit_code }}

            Test Parameters:
            - Counter Iterations: ${{ steps.test-params.outputs.counter_iters }}
            - Create Iterations: ${{ steps.test-params.outputs.create_iters }}
            - Update Iterations: ${{ steps.test-params.outputs.update_iters }}
            - Delete Iterations: ${{ steps.test-params.outputs.delete_iters }}
            - Cycle Count: ${{ steps.test-params.outputs.cycle_count }}

            Directory Structure:
            $(find "$TEST_BASE_DIR" -type f | head -20 | sed 's/^/  - /')

            Total Files: $(find "$TEST_BASE_DIR" -type f | wc -l)
            Total Size: $(du -sh "$TEST_BASE_DIR" 2>/dev/null | awk '{print $1}' || echo "Unknown")
            MANIFEST_EOF

            # Create compressed archive
            echo "Creating archive: $ARCHIVE_NAME"
            tar -czf "$ARCHIVE_NAME" -C "$(dirname "$TEST_BASE_DIR")" "$(basename "$TEST_BASE_DIR")"

            # Verify archive was created
            if [ -f "$ARCHIVE_NAME" ]; then
              ARCHIVE_SIZE=$(ls -lh "$ARCHIVE_NAME" | awk '{print $5}')
              echo "Archive created successfully: $ARCHIVE_NAME ($ARCHIVE_SIZE)"

              # Display archive contents summary
              echo "Archive contains:"
              tar -tzf "$ARCHIVE_NAME" | head -10
              echo "..."
              tar -tzf "$ARCHIVE_NAME" | wc -l
              echo "files total"
            else
              echo "ERROR: Failed to create archive!" >&2
              exit 1
            fi
          else
            echo "Test base directory not found or empty, skipping data upload"
          fi

      - name: Upload test data directory
        if: always() && ${{ inputs.enable_disk_monitoring }}
        uses: actions/upload-artifact@v4
        with:
          name: pruner-test-data-${{ github.run_number }}
          path: pruner-test-data-*.tar.gz
          retention-days: 7
          if-no-files-found: warn

      - name: Post report summary
        if: always()
        run: |
          if [ -f test-report.md ]; then
            cat test-report.md >> $GITHUB_STEP_SUMMARY
          fi

      - name: Cleanup test environment
        if: always()
        run: |
          # Kill any remaining rooch processes
          pkill -f "rooch server" || true

          # Stop disk monitor if still running
          if [ -n "${{ steps.disk-setup.outputs.monitor_pid }}" ]; then
            kill ${{ steps.disk-setup.outputs.monitor_pid }} 2>/dev/null || true
          fi

          # Clean up test data directory (only after artifacts are uploaded)
          if [ -n "${{ steps.disk-setup.outputs.test_base_dir }}" ]; then
            echo "Cleaning up test data directory: ${{ steps.disk-setup.outputs.test_base_dir }}"
            rm -rf "${{ steps.disk-setup.outputs.test_base_dir }}" || true
          fi

          # Clean up monitoring files
          rm -f /tmp/disk_monitor.sh /tmp/disk_usage.log

          # Clean up archive file to save disk space on runner
          rm -f pruner-test-data-*.tar.gz || true
