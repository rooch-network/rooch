The Triple Iron Curtains before Data Availability

popcnt
Rooch Network
Jun 13, 2023

简介

DA 作为审计跟踪必要的持久化层，是整个 Layer2 系统吞吐的瓶颈。于是 DAC 成为了 DA 的一种相对放松的实现成为了不少人的选择。

图1: DA 是漏斗的出口
我们固然希望 DAC 或是别的什么东西既能突破性能桎梏又能完全达到与 Layer1 一致的安全性。有趣的是，我们也明白这等于要求 Layer1 自身突破自身，于是我们不得不要放松一些 DA 与 Layer1 的联系。最直接的方式是缩小网络规模另起炉灶得到一个 mini Blockchain，当网络足够小时， DAC 若影若现。但这样的思路是 Layer1 的不可能三角漩涡的涟漪，并没有把 Layer2 作为视角的核心。这也是 DAC 很容易招致本能反感的直接原因，因为其总是表现为一个依赖信任的区块链。

在本文中，我提出了 DA 的关键安全假设，并基于这个假设得到 “DA身前的三重铁幕”，即构建 DA 的关键问题，以指导我们的工程实践。

DA，无共识复制

	要想真正使用 DA，其安全性假设必须足够简单，能够以一句话阐述上下界，而不是利用人们对确定性的向往兜售复杂而华丽的预言。易于理解的安全假设能吸引更多的参与者，从而有机会形成安全自我增强。并在此基础上谨慎的进行工程实践处理安全假设下衍生出的子问题。

	既然从 Layer2 的视角出发，我们先来看看 DA 在 Layer2 标准模型中的作用:


图2: Sequencer Verifier 同步因果关系图

	这是一个 Sequencer 与 Verifier 的同步因果关系简图，图中的有向边代表 I/O 因果关系。Sequencer 的输出直接作为 Verifier 的输入接受 Verifier 的验证。这也链上验证基本模型。在以扩容为目的 Layer2 网络中，我们无法保证足够强大的即时验证，故而需要 DA 来作为 Sequencer 与 Verifier 之间的异步通信桥梁：


图3: Sequencer DA Verifier 因果关系图

图3可以清晰的反映出关于 DA 的第一个重大设计问题 —— DA 是否对数据内容有决定权？换句话说，就是 DA 可否通过内部共识选择正确的数据块并对其他作恶节点进行惩罚？之所以该问题在这里变得异常突出是因为在讨论 DA 时我们通常忽略了来自 Sequencer 的约束作用，而把 DA 作为了孤立的向 Verifier 提供的服务，进而陷入设计上的困境。实际上，在明确指出 Sequencer 作为 DA 的 “因” 之后，关于该问题的讨论才具备完整意义。我们不难发现，DA 无论如何设计其共识达成的共识也无非是 Sequencer 在 Layer1 的输出，那么 DA 自身的共识就好比在太平洋里倒了一杯水一般微不足道。自我实现是 Layer1 的招魂术，需要庞大的经济网络支撑其预言自我增强。

基于以上的讨论，我们有了对于 DA 的初步安全假设：

基于经济博弈实现开放性复制网络，在大规模罢工下通过 Layer1 和存活数据修复。

对比一下 Layer1 的安全假设：

基于经济博弈实现开放性拜占庭容错网络，在大规模分歧下通过自我分叉修复。

看上去似乎不错！

在有了基础安全假设（下限明确）之后，我们需要对其进一步增强。作为存储组件，最自然的角度是 I/O 出发。那么我们期望其尽可能的满足：

（1）确保数据被正确写入并保存
（2）确保读取有响应
（3）确保读取响应的完整性

让我们继续吧！

第一道铁幕：持久化证明

我们先来看看 DA 的第一道铁幕，它等价于如何证明一条水管里流出来的水是来自它自己的蓄水池里的还是从别的地方抽过来的？水在何处都是 H₂O。这个似乎无解的问题正是 DA 不得不面对一个问题，这是因为在 DA 中每一份数据有公开的多节点可访问冗余，那么只要有一个持有该份数据的诚实节点，其他节点都可以转发客户端的读取请求。

这个问题最严重的代价并不是不当得利，而是所面临的可靠性风险。这个风险在不同的 DA 数据分布形态中有不同的表现：

（1）基于 Erasure Code 的条带化分布：对于  （k 份原始数据，m份冗余数据）条带， n 个节点，数据均匀分布。至少需要有 个诚实节点。
（2）基于完全复制分布：n 个节点各有一份完整数据。至少需要有 1 个诚实节点。

很显然，不加以控制这样的风险，我们原先偏爱的可以减少 DA 节点负担的 Erasure Code 方案会带来更大的风险，因为需要的诚实节点数目更大。考虑到对于准入门槛较高的 DAC 来说，成员数目有限，每个成员持有完整数据的总体开销则是可以接受的。

让我们回到本小节一开始提到的证明“水是水”的问题。其实水也不是凭空创造的，它也有起因。从水的起因到生成水的结果这一过程我们可以称之为状态（变迁）距离，比如我们可以很轻而易举的证明我眼前这杯水不是我三秒钟前从喜马拉雅山脉采集的雪水，因为我的速度不足以让我实现这么短的状态距离。基于这一点基本常识，我们可以试图构建证明了：

（1）基本前提：DA 节点收到了准确的数据，并响应了 Sequencer 的写入请求
（2）访问远端存储的状态距离远大于本地存储

对于 （1）由于 Sequencer 是 DA 数据的起因，那么 Sequencer 可以持有两份关于数据的摘要，第一份用于端到端校验，第二份作为 DA 上存储数据的 hash。因为无从得知该 hash 值，DA 不得不完全下载全量数据并将计算的 hash 返回给 Sequencer 验证。关于 （1） 的解决方案多种多样，需要结合具体的 DA 网络架构设计。需要做到的是避免 DA 不执行实际下载即可。

至于（2）实际上社区也已经做了很多有趣的工作，究其本质都是在尽量减少区块链智能合约开销下的提供基于状态距离的持久化证明：


图4: 状态距离

我们需要 t0 （证明生成时间）与 t1 （本地 I/O 时间）之和小于证明提交期限。为了明显区别于 t2 （远程 I/O），我们这个和尽可能的小于它。这一点我们可以通过反复大量的随机 I/O 实现，以期望碎片化的请求造成的网络开销显著增长。
状态距离作为强证据（尤其是多轮过后）可以有效识别 DA 节点的不作为，在未来也可以不断迭代算法和动态调整参数以加强效力。不过需要意识到的是，如果一切检查都要走公链合约执行，其低效必然导致其成为摆设。因此链下生成证明成为了诸多人的选择，比如利用 Zero-knowledge 很受欢迎。

另外，我们必须明确的是 DA 负责的对象是 Layer2 ，因此在 Layer2 发起的检查是正确的做法，如果 Layer2 作弊将无法通过欺诈证明。为了在 Optimistic Rollup 中进一步提升检查效率，我们可以用交互式证明的方式工作：

Sequencer 按照固定尺寸将数据切成固定数量的切片，并组成  merkle tree。其中 root （下称 object_root) 将等待 DA 返回后验证
挑战者生成大量切片 range（如切片1中 [0,256) 字节），并将 range 列表中的数据组成 merkle tree。该列表由挑战者的随机数种子生成
挑战者以随机数种子通过 L2 向某个 DA 服务方方发起挑战。若被挑战者满足挑战周期（如七天未被挑战）则挑战发起有效
被挑战方根据随机数种子生成 range list，并将在合约规定时间内生成 merkle tree root。否则被惩罚
挑战者上传自己的 merkle tree root，如果不匹配。双方通过二分查找找到第一个不匹配的 range hash
挑战者与被挑战者均提交该不一致 range 所在的切片，以及切片在 object_root 中的证明
合约验证切片存在证明。证明无效则进行相应惩罚

考虑到 DA 服务提供方仅是个去中心化的中继节点，实际存储可能在远端，而远端存储很有可能不支持 range 请求。该挑战机制将在初期仅实现切片和摘要算法功能，为以后的升级做准备。





第二道铁幕：无响应攻击

	无响应攻击是无解的两将军问题在 DA 中的具体体现，DA 节点可以有选择性的响应客户端的请求同时伪装成网络不可达。惩罚这类行为的前提是我们对 DA 节点的可用性有预期，即我们对 DA 节点的服务可用性有准确要求。

	对于 Layer2 来说，即时的大规模的读取需求主要来自于 Verifier 节点，Verifier 作为 Layer2 网络的安全防线自然是可以承担对 DA 可用性检测的责任的，否则 Layer2 网络不成立。在这个前提下， Verifiers 作为处理两将军问题的相对权威第三方是可以接受的。
	
	因此通过 Verifiers 作用于对抗无响应攻击的最直接方式是：

	Verifiers 通过匿藏真实请求地址的方式请求 DA 从而避免 DA 对请求进行识别，并记录 DA 节点的响应质量。将该数据定期作为 tx 定期写入到 Layer2 中以供 DAO 裁决。DAO 将对 DA 的服务质量进行投票，对不满足条件的节点进行惩罚，对表现优异的节点予以奖励，并实现 DA 服务方轮替。

	再此基础之上，我们还可以提供智能合约版本的无响应验证。即发起 Layer2 交易要求无响应节点在一定时间内提供数据。这样的做法的一大问题是脱离了“犯罪现场”，这与 Verifier 的直接参与有着本质不同。发起请求和搜集请求结果的是同一方才能保证完整的因果关系链条。DA 节点没有理由不响应会带来直接惩罚的链上合约。这里可以另外延伸出一个话题，即间接证据的重要性。回到智能合约约束上，我们自然还可以利用 Layer1 进行更有权威性的挑战，但由于效率问题几乎难以工作。

	简而言之，无响应攻击的探测必须承认第一现场的时空局限性。

第三道铁幕：错误响应攻击

	DA 还有第三种关键作弊武器，也是容易被忽视的，少见讨论，因为其背后的问题是如此“沉默”。Silent Data Corruption 实际上无处不在，但由于其发生的概率较低或是被认为较低，总是得不到有效的保护。在互联网历史上，由于它造成的损失不计其数。那么它对 Web3 世界，尤其是我们现在讨论的 Layer2 网络有多大影响呢？

	不同于 Layer1，Layer2 网络基于较少的节点（部分服务可认为对外暴露的是一台逻辑服务器），在当我们不得不依赖单点的时候，静默错误就开始粉墨登场。毕竟，当你自己都不知道自己错误的情况下如何指正自己的错误呢？而 DA 节点恰好可以利用这一点伪装自己的恶意。它完全可以返回错误响应并表示自己只是很不幸的碰上了静默错误，那么如何区分恶意与无奈？一棒子打死所有错误响应是十分不妥的，因为静默错误出现的概率远比想象中高！
	
	和处理无响应错误一样，我们需要先建立服务质量预期，在这里主要是网络传输的误码率。解决这个问题的办法很成熟了，也就是无处不在的纠错码。在纠错范围内，DA 节点的恶意毫无意义，在纠错范围外，我们认为 DA 节点主观作弊了。

	又如无响应错误一样，这里涉及到事故现场问题。同样的，我们可以引入 Verifier 来提供 DA 节点的原始作弊证据。智能合约的直接判定方式在此不起作用的主要原因也跟上文相同，不再赘述。纠错码的使用代价很低，随时开启它也不会造成吞吐效率的下降。

再谈 DA 角色
DA 最近（其实很早就开始了）在概念上进行了进一步明确，从它实际的作用看，它更应该被称为 DP （Data Publication)，如此一来它和永久存储的 Data Storage 就明确区分了出来。

在我看来，DA 完全可以作为 DP 和 DS（Data Storage）的抽象层。当我们的存储策略是数据发布时，它表现为 DP，当我们的存储策略是永久存储时，它表现为 DS：











前文提到的 DA 的基础安全假设是建立在整个 Layer2 组建以及 Layer1 的相互合作，撕咬之上的。同时，我也提到 DAO 需要有备份机制为 DA 安全假设的最差情况兜底。那么如何将这样的模糊期望具体化呢？其关键点有两条：

（1）DA 支持异质存储
（2）DA 支持充分竞争的市场化运作

（1）我们知道 DA 是数据存储的巨大缓冲器，它对于突发流量增长的支撑能力决定了 Layer2 网络的上限。与此同时，我们并不总是面临这样的数据洪流，综合高峰低谷，DA 的服务能力是过剩的。那么，较为慢速的 DA 之外存储是可以充当备份功能的。要实现 （1）的隐含条件是：

DA 各节点在服务上是均质的，但服务实现是可以异质的。

即每一个节点都能提供尽可能完整的数据访问。如此一来，我们的备份甚至可以不局限于地表的大陆。没有理由不将历史数据沉入海底，或者发射上天，什么能阻止我们这样做呢？毕竟一旦拿到数据就是开箱可用的。

1/n 信任模型还可以更好的支撑条件 （2）。对于一家新兴公司，其产品没有出现在大企业的采购目录中是非常自然的。待其产品和服务取得竞争优势，称为供应商也是非常自然的。我们需要将这样自然的过程注入到 DA 的水杯之中。因为服务是均质的，任何人可以在尚未加入 DA 网络之前对外提供数据服务，它不需要任何许可，它不需要和其他组建打交道以理解元数据组织并进行复杂的同步过程。如果它做的更好，DAO 会兴高采烈的迎接它的加入并用它取代表现不佳的节点。市场竞争对僵化的白名单模式是极具破坏力的，这样的暴力是我期望的。美德建立在运用暴力的能力之上，如果没有破坏力也就谈不上自我约束，美德也就成了软弱的修辞，高悬的达摩克利斯之剑反射的耀眼寒光令人彬彬有礼。



